# Superstore ETL & Data Warehouse Project

Este projeto demonstra um pipeline de Engenharia de Dados completo, realizando a extra√ß√£o de dados brutos de um CSV (Superstore dataset), processamento de limpeza e normaliza√ß√£o, e carga em um **Data Warehouse** modelado em **Star Schema** utilizando PostgreSQL.

---

## Arquitetura do Projeto

O projeto segue a arquitetura **Medallion-like** simplificada:
1.  **Staging Area:** Dados brutos carregados diretamente do CSV com tipagem b√°sica.
2.  **Transform Layer:** Limpeza de nulos, padroniza√ß√£o de strings e valida√ß√£o de integridade.
3.  **Data Warehouse (DW):** Modelagem dimensional (Fatos e Dimens√µes) para otimiza√ß√£o de consultas e BI.



---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.x
* **Manipula√ß√£o de Dados:** Pandas
* **Banco de Dados:** PostgreSQL (Rodando via Docker)
* **ORM/Interface:** SQLAlchemy & Psycopg2
* **Visualiza√ß√£o:** Power BI

---

## Modelagem Dimensional (Star Schema)

A estrutura do Data Warehouse foi desenhada para facilitar a an√°lise de performance de vendas:

* **Tabela Fato:** `fact_sales` (Cont√©m m√©tricas e chaves estrangeiras).
* **Tabelas Dimens√£o:** * `dim_customer`: Dados dos clientes.
    * `dim_product`: Informa√ß√µes dos produtos.
    * `dim_location`: Localiza√ß√£o geogr√°fica das vendas.
    * `dim_date`: Dimens√£o tempo (granularidade de dia).
    * `dim_ship_mode`: Modos de envio.



---

## Arquitetura do Projeto

![Estrutura do Projeto](img/structure.png)

## Como Executar o Projeto



1.  **Configurar o ambiente:**
    Renomeie o `.env.example` para `.env` e preencha suas credenciais.

2.  **Subir o Banco de Dados:**
    ```bash
    docker-compose up -d
    ```

3.  **Executar o Pipeline:**
    O projeto possui um orquestrador central que executa os passos na ordem correta:
    ```bash
    python etl/main.py
    ```

---

## Data Quality (Diagn√≥stico)

Um diferencial deste projeto √© a fase de **Data Quality**, onde realizamos o diagn√≥stico de `nunique` para identificar:
- Inconsist√™ncias de escrita (Ex: "Londres" vs "londres").
- Erros de integridade (1 ID de produto para m√∫ltiplos nomes).
- Monitoramento de valores nulos em colunas cr√≠ticas.



---

## Boas Pr√°ticas Aplicadas

- Separa√ß√£o Staging √ó Data Warehouse
- Modelagem Star Schema
- Uso de vari√°veis de ambiente (.env)
- Containeriza√ß√£o com Docker
- Pipeline reexecut√°vel (reload seguro)
- Valida√ß√£o autom√°tica de dados

---

**Desenvolvido por [Josu√© Alexandre]**